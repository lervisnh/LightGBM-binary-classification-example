{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using LightGBM classifier on credit card user data to predict default rate\n",
    "\n",
    "This notebook utilizes the LightGBM package by Microsoft with a clean dataset on credit card defaults (source: https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients). Since we are trying to predict if a person is defaulting or not, we will want to use binary classification. This notebook also explores early stopping, a form of regularization used to avoid overfitting when training a learner with an iterative method, such as gradient descent. Such methods update the learner so as to make it better fit the training data with each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc, accuracy_score, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('ccdata.xls', header = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This research employed a binary variable, default payment (Yes = 1, No = 0), as the response variable. This study reviewed the literature and used the following 23 variables as explanatory variables:\n",
    "- X1: Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit.\n",
    "- X2: Gender (1 = male; 2 = female).\n",
    "- X3: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others).\n",
    "- X4: Marital status (1 = married; 2 = single; 3 = others).\n",
    "- X5: Age (year).\n",
    "- X6 - X11: History of past payment. We tracked the past monthly payment records (from April to September, 2005) as follows: X6 = the repayment status in September, 2005; X7 = the repayment status in August, 2005; . . .;X11 = the repayment status in April, 2005. The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above.\n",
    "- X12-X17: Amount of bill statement (NT dollar). X12 = amount of bill statement in September, 2005; X13 = amount of bill statement in August, 2005; . . .; X17 = amount of bill statement in April, 2005.\n",
    "- X18-X23: Amount of previous payment (NT dollar). X18 = amount paid in September, 2005; X19 = amount paid in August, 2005; . . .;X23 = amount paid in April, 2005.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('ID', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values. \n",
    "data.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank god there are no missing values! If there were, we would have to either drop the feature if \n",
    "there are more than 60% of the values are missing, or impute them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier Detection in this cell.\n",
    "# For each column, first it computes the Z-score of each value in the column,\n",
    "# relative to the column mean and standard deviation. Then is takes the absolute \n",
    "# of Z-score because the direction does not matter, only if it is below the threshold.\n",
    "# all(axis=1) ensures that for each row, all column satisfy the constraint. \n",
    "data = data[data.apply(lambda x: np.abs(x - x.mean()) / x.std() < 3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below, we separate our target variable from our dataset. \n",
    "X = data.drop(['default payment next month'], axis=1)\n",
    "y = data['default payment next month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's then put 85% of our dataset into a training set and 15% of it into a test set. \n",
    "# We can use random_state because it is not a time series dataset that we are using.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>LightGBM classifier hyperparameter optimization via scikit-learn's GridSearchCV</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "estimator = lgb.LGBMClassifier(learning_rate = 0.125, metric = 'l1', \n",
    "                        n_estimators = 20, num_leaves = 38)\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [x for x in range(24,40,2)],\n",
    "    'learning_rate': [0.10, 0.125, 0.15, 0.175, 0.2]}\n",
    "gridsearch = GridSearchCV(estimator, param_grid)\n",
    "\n",
    "gridsearch.fit(X_train, y_train,\n",
    "        eval_set = [(X_test, y_test)],\n",
    "        eval_metric = ['auc', 'binary_logloss'],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=5),\n",
    "        ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best parameters found by grid search are:', gridsearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>LightGBM Hyperparameters + early stopping</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5030, number of negative: 17434\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012523 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3203\n",
      "[LightGBM] [Info] Number of data points in the train set: 22464, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.223914 -> initscore=-1.243002\n",
      "[LightGBM] [Info] Start training from score -1.243002\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.77497\tvalid_0's binary_logloss: 0.438562\tvalid_0's l1: 0.281158\tvalid_0's l2: 0.137763\tvalid_0's binary_error: 0.180328\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-22 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-22 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-22 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-22 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-22 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-22 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-22 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-22 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-22 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-22 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-22 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-22 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-22 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-22 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-22 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-22 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-22 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-22 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-22 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-22 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-22 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-22 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-22 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-22 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-22 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-22 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-22 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-22 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-22 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-22 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-22 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-22 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-22 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-22 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-22 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-22 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-22 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-22 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-22 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-22 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-22 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-22 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-22\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.15, metric=&#x27;binary_error&#x27;, n_estimators=200,\n",
       "               reg_alpha=0.1, reg_lambda=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" checked><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LGBMClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(learning_rate=0.15, metric=&#x27;binary_error&#x27;, n_estimators=200,\n",
       "               reg_alpha=0.1, reg_lambda=0.1)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(learning_rate=0.15, metric='binary_error', n_estimators=200,\n",
       "               reg_alpha=0.1, reg_lambda=0.1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "gbm = lgb.LGBMClassifier(learning_rate = 0.15, metric = 'binary_error', \n",
    "                         reg_alpha = 0.1,\n",
    "                         reg_lambda = 0.1,\n",
    "                        n_estimators = 200,)\n",
    "\n",
    "\n",
    "gbm.fit(X_train, y_train,\n",
    "        eval_set=[(X_test, y_test)],\n",
    "        eval_metric=['auc', 'binary_logloss','l1', 'l2'],\n",
    "        callbacks=[\n",
    "                lgb.early_stopping(stopping_rounds=5),\n",
    "        ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Feature Importances Graph </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = lgb.plot_importance(gbm, height = 0.4, \n",
    "                         max_num_features = 25, \n",
    "                         xlim = (0,100), ylim = (0,23), \n",
    "                         figsize = (10,6))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Dimensionality reduction using feature importances</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[53,\n",
       " 38,\n",
       " 32,\n",
       " 31,\n",
       " 29,\n",
       " 27,\n",
       " 26,\n",
       " 24,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 18,\n",
       " 18,\n",
       " 15,\n",
       " 14,\n",
       " 11,\n",
       " 10,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 3]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each feature of our dataset, the result of the following\n",
    "# code snippet contains numbers of times a feature is used in a model.\n",
    "sorted(gbm.feature_importances_,reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n",
      "38\n",
      "32\n",
      "31\n",
      "29\n",
      "27\n",
      "26\n",
      "24\n",
      "20\n",
      "19\n",
      "19\n",
      "19\n",
      "18\n",
      "18\n",
      "15\n",
      "15 0.8622222222222222\n"
     ]
    }
   ],
   "source": [
    "# The code below aims to drop  to keep the features that are included in the most important features. \n",
    "temp = 0 \n",
    "total = sum(gbm.feature_importances_)\n",
    "for feature in sorted(gbm.feature_importances_, reverse=True):\n",
    "    temp+=feature\n",
    "    print(feature)\n",
    "    if temp/total >= 0.85:\n",
    "        print(feature,temp/total) # stop when we \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC without dimensionality reduction: \n",
      "0.7749700285270646\n"
     ]
    }
   ],
   "source": [
    "#The above means let go of all variables after PAY_AMT_5\n",
    "y_pred_prob = gbm.predict_proba(X_test)[:, 1]\n",
    "auc_roc_0 = str(roc_auc_score(y_test, y_pred_prob)) # store AUC score without dimensionality reduction\n",
    "print('AUC without dimensionality reduction: \\n' + auc_roc_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can choose to drop the last 6 features from in our new model to reduce dimensionality, and thus save training time and space\n",
    "\n",
    "X = X.drop(['PAY_5','PAY_AMT4','BILL_AMT4','BILL_AMT2','BILL_AMT6','EDUCATION','BILL_AMT5','BILL_AMT3'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001073 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.772414\tvalid_0's binary_logloss: 0.482576\tvalid_0's l1: 0.326741\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.779927\tvalid_0's binary_logloss: 0.472575\tvalid_0's l1: 0.320921\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.773427\tvalid_0's binary_logloss: 0.481936\tvalid_0's l1: 0.326297\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000207 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's auc: 0.775056\tvalid_0's binary_logloss: 0.434402\tvalid_0's l1: 0.282558\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.774191\tvalid_0's binary_logloss: 0.473013\tvalid_0's l1: 0.321235\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000227 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.772414\tvalid_0's binary_logloss: 0.482576\tvalid_0's l1: 0.326741\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.779927\tvalid_0's binary_logloss: 0.472575\tvalid_0's l1: 0.320921\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.773427\tvalid_0's binary_logloss: 0.481936\tvalid_0's l1: 0.326297\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's auc: 0.775056\tvalid_0's binary_logloss: 0.434402\tvalid_0's l1: 0.282558\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000147 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.774191\tvalid_0's binary_logloss: 0.473013\tvalid_0's l1: 0.321235\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.772414\tvalid_0's binary_logloss: 0.482576\tvalid_0's l1: 0.326741\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.779927\tvalid_0's binary_logloss: 0.472575\tvalid_0's l1: 0.320921\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.773427\tvalid_0's binary_logloss: 0.481936\tvalid_0's l1: 0.326297\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's auc: 0.775056\tvalid_0's binary_logloss: 0.434402\tvalid_0's l1: 0.282558\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.774191\tvalid_0's binary_logloss: 0.473013\tvalid_0's l1: 0.321235\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000226 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.772414\tvalid_0's binary_logloss: 0.482576\tvalid_0's l1: 0.326741\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000231 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.779927\tvalid_0's binary_logloss: 0.472575\tvalid_0's l1: 0.320921\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001938 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.773427\tvalid_0's binary_logloss: 0.481936\tvalid_0's l1: 0.326297\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's auc: 0.775056\tvalid_0's binary_logloss: 0.434402\tvalid_0's l1: 0.282558\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.774191\tvalid_0's binary_logloss: 0.473013\tvalid_0's l1: 0.321235\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.772414\tvalid_0's binary_logloss: 0.482576\tvalid_0's l1: 0.326741\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000181 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.779927\tvalid_0's binary_logloss: 0.472575\tvalid_0's l1: 0.320921\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.773427\tvalid_0's binary_logloss: 0.481936\tvalid_0's l1: 0.326297\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's auc: 0.775056\tvalid_0's binary_logloss: 0.434402\tvalid_0's l1: 0.282558\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001915 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.774191\tvalid_0's binary_logloss: 0.473013\tvalid_0's l1: 0.321235\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000249 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.772414\tvalid_0's binary_logloss: 0.482576\tvalid_0's l1: 0.326741\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.779927\tvalid_0's binary_logloss: 0.472575\tvalid_0's l1: 0.320921\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000442 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.773427\tvalid_0's binary_logloss: 0.481936\tvalid_0's l1: 0.326297\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's auc: 0.775056\tvalid_0's binary_logloss: 0.434402\tvalid_0's l1: 0.282558\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.774191\tvalid_0's binary_logloss: 0.473013\tvalid_0's l1: 0.321235\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.772414\tvalid_0's binary_logloss: 0.482576\tvalid_0's l1: 0.326741\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000810 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.779927\tvalid_0's binary_logloss: 0.472575\tvalid_0's l1: 0.320921\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000242 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.773427\tvalid_0's binary_logloss: 0.481936\tvalid_0's l1: 0.326297\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000208 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's auc: 0.775056\tvalid_0's binary_logloss: 0.434402\tvalid_0's l1: 0.282558\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.774191\tvalid_0's binary_logloss: 0.473013\tvalid_0's l1: 0.321235\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000148 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.772414\tvalid_0's binary_logloss: 0.482576\tvalid_0's l1: 0.326741\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000149 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.779927\tvalid_0's binary_logloss: 0.472575\tvalid_0's l1: 0.320921\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000248 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.773427\tvalid_0's binary_logloss: 0.481936\tvalid_0's l1: 0.326297\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000231 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's auc: 0.775056\tvalid_0's binary_logloss: 0.434402\tvalid_0's l1: 0.282558\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.774191\tvalid_0's binary_logloss: 0.473013\tvalid_0's l1: 0.321235\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000224 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.773408\tvalid_0's binary_logloss: 0.452802\tvalid_0's l1: 0.306232\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.775923\tvalid_0's binary_logloss: 0.474429\tvalid_0's l1: 0.322064\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.77156\tvalid_0's binary_logloss: 0.486299\tvalid_0's l1: 0.328914\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[19]\tvalid_0's auc: 0.774246\tvalid_0's binary_logloss: 0.4334\tvalid_0's l1: 0.279374\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000242 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.773203\tvalid_0's binary_logloss: 0.474557\tvalid_0's l1: 0.322289\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.773408\tvalid_0's binary_logloss: 0.452802\tvalid_0's l1: 0.306232\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000226 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.775923\tvalid_0's binary_logloss: 0.474429\tvalid_0's l1: 0.322064\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.77156\tvalid_0's binary_logloss: 0.486299\tvalid_0's l1: 0.328914\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000148 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's auc: 0.774246\tvalid_0's binary_logloss: 0.4334\tvalid_0's l1: 0.279374\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.773203\tvalid_0's binary_logloss: 0.474557\tvalid_0's l1: 0.322289\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000149 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.773408\tvalid_0's binary_logloss: 0.452802\tvalid_0's l1: 0.306232\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000230 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.775923\tvalid_0's binary_logloss: 0.474429\tvalid_0's l1: 0.322064\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000231 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.77156\tvalid_0's binary_logloss: 0.486299\tvalid_0's l1: 0.328914\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's auc: 0.774246\tvalid_0's binary_logloss: 0.4334\tvalid_0's l1: 0.279374\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000234 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.773203\tvalid_0's binary_logloss: 0.474557\tvalid_0's l1: 0.322289\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.773408\tvalid_0's binary_logloss: 0.452802\tvalid_0's l1: 0.306232\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000224 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.775923\tvalid_0's binary_logloss: 0.474429\tvalid_0's l1: 0.322064\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.77156\tvalid_0's binary_logloss: 0.486299\tvalid_0's l1: 0.328914\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000184 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's auc: 0.774246\tvalid_0's binary_logloss: 0.4334\tvalid_0's l1: 0.279374\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000325 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.773203\tvalid_0's binary_logloss: 0.474557\tvalid_0's l1: 0.322289\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000177 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.773408\tvalid_0's binary_logloss: 0.452802\tvalid_0's l1: 0.306232\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.775923\tvalid_0's binary_logloss: 0.474429\tvalid_0's l1: 0.322064\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.77156\tvalid_0's binary_logloss: 0.486299\tvalid_0's l1: 0.328914\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000184 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's auc: 0.774246\tvalid_0's binary_logloss: 0.4334\tvalid_0's l1: 0.279374\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000250 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.773203\tvalid_0's binary_logloss: 0.474557\tvalid_0's l1: 0.322289\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000228 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.773408\tvalid_0's binary_logloss: 0.452802\tvalid_0's l1: 0.306232\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000215 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.775923\tvalid_0's binary_logloss: 0.474429\tvalid_0's l1: 0.322064\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.77156\tvalid_0's binary_logloss: 0.486299\tvalid_0's l1: 0.328914\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's auc: 0.774246\tvalid_0's binary_logloss: 0.4334\tvalid_0's l1: 0.279374\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000149 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.773203\tvalid_0's binary_logloss: 0.474557\tvalid_0's l1: 0.322289\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.773408\tvalid_0's binary_logloss: 0.452802\tvalid_0's l1: 0.306232\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.775923\tvalid_0's binary_logloss: 0.474429\tvalid_0's l1: 0.322064\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000203 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.77156\tvalid_0's binary_logloss: 0.486299\tvalid_0's l1: 0.328914\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000150 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's auc: 0.774246\tvalid_0's binary_logloss: 0.4334\tvalid_0's l1: 0.279374\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.773203\tvalid_0's binary_logloss: 0.474557\tvalid_0's l1: 0.322289\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.773408\tvalid_0's binary_logloss: 0.452802\tvalid_0's l1: 0.306232\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000148 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.775923\tvalid_0's binary_logloss: 0.474429\tvalid_0's l1: 0.322064\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.77156\tvalid_0's binary_logloss: 0.486299\tvalid_0's l1: 0.328914\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's auc: 0.774246\tvalid_0's binary_logloss: 0.4334\tvalid_0's l1: 0.279374\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.773203\tvalid_0's binary_logloss: 0.474557\tvalid_0's l1: 0.322289\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.773632\tvalid_0's binary_logloss: 0.459014\tvalid_0's l1: 0.311643\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.777105\tvalid_0's binary_logloss: 0.467805\tvalid_0's l1: 0.318008\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000227 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.774335\tvalid_0's binary_logloss: 0.479974\tvalid_0's l1: 0.325648\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000150 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.775549\tvalid_0's binary_logloss: 0.433302\tvalid_0's l1: 0.279172\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000195 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.776468\tvalid_0's binary_logloss: 0.443114\tvalid_0's l1: 0.296659\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.773632\tvalid_0's binary_logloss: 0.459014\tvalid_0's l1: 0.311643\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001049 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.777105\tvalid_0's binary_logloss: 0.467805\tvalid_0's l1: 0.318008\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000229 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.774335\tvalid_0's binary_logloss: 0.479974\tvalid_0's l1: 0.325648\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000233 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.775549\tvalid_0's binary_logloss: 0.433302\tvalid_0's l1: 0.279172\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.776468\tvalid_0's binary_logloss: 0.443114\tvalid_0's l1: 0.296659\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.773632\tvalid_0's binary_logloss: 0.459014\tvalid_0's l1: 0.311643\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000575 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.777105\tvalid_0's binary_logloss: 0.467805\tvalid_0's l1: 0.318008\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.774335\tvalid_0's binary_logloss: 0.479974\tvalid_0's l1: 0.325648\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000219 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.775549\tvalid_0's binary_logloss: 0.433302\tvalid_0's l1: 0.279172\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.776468\tvalid_0's binary_logloss: 0.443114\tvalid_0's l1: 0.296659\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000246 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.773632\tvalid_0's binary_logloss: 0.459014\tvalid_0's l1: 0.311643\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000704 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.777105\tvalid_0's binary_logloss: 0.467805\tvalid_0's l1: 0.318008\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000207 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.774335\tvalid_0's binary_logloss: 0.479974\tvalid_0's l1: 0.325648\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.775549\tvalid_0's binary_logloss: 0.433302\tvalid_0's l1: 0.279172\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000717 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.776468\tvalid_0's binary_logloss: 0.443114\tvalid_0's l1: 0.296659\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.773632\tvalid_0's binary_logloss: 0.459014\tvalid_0's l1: 0.311643\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.777105\tvalid_0's binary_logloss: 0.467805\tvalid_0's l1: 0.318008\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.774335\tvalid_0's binary_logloss: 0.479974\tvalid_0's l1: 0.325648\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000231 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.775549\tvalid_0's binary_logloss: 0.433302\tvalid_0's l1: 0.279172\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.776468\tvalid_0's binary_logloss: 0.443114\tvalid_0's l1: 0.296659\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000247 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.773632\tvalid_0's binary_logloss: 0.459014\tvalid_0's l1: 0.311643\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.777105\tvalid_0's binary_logloss: 0.467805\tvalid_0's l1: 0.318008\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.774335\tvalid_0's binary_logloss: 0.479974\tvalid_0's l1: 0.325648\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000248 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.775549\tvalid_0's binary_logloss: 0.433302\tvalid_0's l1: 0.279172\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000228 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.776468\tvalid_0's binary_logloss: 0.443114\tvalid_0's l1: 0.296659\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000209 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.773632\tvalid_0's binary_logloss: 0.459014\tvalid_0's l1: 0.311643\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000227 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.777105\tvalid_0's binary_logloss: 0.467805\tvalid_0's l1: 0.318008\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000226 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.774335\tvalid_0's binary_logloss: 0.479974\tvalid_0's l1: 0.325648\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000147 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.775549\tvalid_0's binary_logloss: 0.433302\tvalid_0's l1: 0.279172\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.776468\tvalid_0's binary_logloss: 0.443114\tvalid_0's l1: 0.296659\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000225 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.773632\tvalid_0's binary_logloss: 0.459014\tvalid_0's l1: 0.311643\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.777105\tvalid_0's binary_logloss: 0.467805\tvalid_0's l1: 0.318008\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000587 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.774335\tvalid_0's binary_logloss: 0.479974\tvalid_0's l1: 0.325648\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.775549\tvalid_0's binary_logloss: 0.433302\tvalid_0's l1: 0.279172\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000229 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.776468\tvalid_0's binary_logloss: 0.443114\tvalid_0's l1: 0.296659\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000206 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.773218\tvalid_0's binary_logloss: 0.462647\tvalid_0's l1: 0.314613\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000274 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.777883\tvalid_0's binary_logloss: 0.461848\tvalid_0's l1: 0.313972\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.768945\tvalid_0's binary_logloss: 0.494413\tvalid_0's l1: 0.333231\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.773681\tvalid_0's binary_logloss: 0.438756\tvalid_0's l1: 0.289845\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.777661\tvalid_0's binary_logloss: 0.437363\tvalid_0's l1: 0.288918\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.773218\tvalid_0's binary_logloss: 0.462647\tvalid_0's l1: 0.314613\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000258 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.777883\tvalid_0's binary_logloss: 0.461848\tvalid_0's l1: 0.313972\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000229 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.768945\tvalid_0's binary_logloss: 0.494413\tvalid_0's l1: 0.333231\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000270 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.773681\tvalid_0's binary_logloss: 0.438756\tvalid_0's l1: 0.289845\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000235 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.777661\tvalid_0's binary_logloss: 0.437363\tvalid_0's l1: 0.288918\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000231 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.773218\tvalid_0's binary_logloss: 0.462647\tvalid_0's l1: 0.314613\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.777883\tvalid_0's binary_logloss: 0.461848\tvalid_0's l1: 0.313972\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000234 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.768945\tvalid_0's binary_logloss: 0.494413\tvalid_0's l1: 0.333231\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.773681\tvalid_0's binary_logloss: 0.438756\tvalid_0's l1: 0.289845\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000226 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.777661\tvalid_0's binary_logloss: 0.437363\tvalid_0's l1: 0.288918\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000228 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.773218\tvalid_0's binary_logloss: 0.462647\tvalid_0's l1: 0.314613\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000230 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.777883\tvalid_0's binary_logloss: 0.461848\tvalid_0's l1: 0.313972\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000307 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.768945\tvalid_0's binary_logloss: 0.494413\tvalid_0's l1: 0.333231\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000286 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.773681\tvalid_0's binary_logloss: 0.438756\tvalid_0's l1: 0.289845\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000149 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.777661\tvalid_0's binary_logloss: 0.437363\tvalid_0's l1: 0.288918\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.773218\tvalid_0's binary_logloss: 0.462647\tvalid_0's l1: 0.314613\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000224 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.777883\tvalid_0's binary_logloss: 0.461848\tvalid_0's l1: 0.313972\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000280 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.768945\tvalid_0's binary_logloss: 0.494413\tvalid_0's l1: 0.333231\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.773681\tvalid_0's binary_logloss: 0.438756\tvalid_0's l1: 0.289845\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000280 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.777661\tvalid_0's binary_logloss: 0.437363\tvalid_0's l1: 0.288918\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000242 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.773218\tvalid_0's binary_logloss: 0.462647\tvalid_0's l1: 0.314613\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001291 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.777883\tvalid_0's binary_logloss: 0.461848\tvalid_0's l1: 0.313972\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.768945\tvalid_0's binary_logloss: 0.494413\tvalid_0's l1: 0.333231\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000149 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.773681\tvalid_0's binary_logloss: 0.438756\tvalid_0's l1: 0.289845\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000147 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.777661\tvalid_0's binary_logloss: 0.437363\tvalid_0's l1: 0.288918\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000222 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.773218\tvalid_0's binary_logloss: 0.462647\tvalid_0's l1: 0.314613\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000229 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.777883\tvalid_0's binary_logloss: 0.461848\tvalid_0's l1: 0.313972\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000221 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.768945\tvalid_0's binary_logloss: 0.494413\tvalid_0's l1: 0.333231\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.773681\tvalid_0's binary_logloss: 0.438756\tvalid_0's l1: 0.289845\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000233 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.777661\tvalid_0's binary_logloss: 0.437363\tvalid_0's l1: 0.288918\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000238 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.773218\tvalid_0's binary_logloss: 0.462647\tvalid_0's l1: 0.314613\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000234 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.777883\tvalid_0's binary_logloss: 0.461848\tvalid_0's l1: 0.313972\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.768945\tvalid_0's binary_logloss: 0.494413\tvalid_0's l1: 0.333231\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000247 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.773681\tvalid_0's binary_logloss: 0.438756\tvalid_0's l1: 0.289845\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000371 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.777661\tvalid_0's binary_logloss: 0.437363\tvalid_0's l1: 0.288918\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000503 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.772696\tvalid_0's binary_logloss: 0.444792\tvalid_0's l1: 0.297906\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001010 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.775311\tvalid_0's binary_logloss: 0.436933\tvalid_0's l1: 0.288174\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000254 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.768945\tvalid_0's binary_logloss: 0.49023\tvalid_0's l1: 0.33133\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000910 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.773262\tvalid_0's binary_logloss: 0.440887\tvalid_0's l1: 0.293259\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000230 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.777838\tvalid_0's binary_logloss: 0.437697\tvalid_0's l1: 0.288775\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000257 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.772696\tvalid_0's binary_logloss: 0.444792\tvalid_0's l1: 0.297906\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000191 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.775311\tvalid_0's binary_logloss: 0.436933\tvalid_0's l1: 0.288174\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.768945\tvalid_0's binary_logloss: 0.49023\tvalid_0's l1: 0.33133\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.773262\tvalid_0's binary_logloss: 0.440887\tvalid_0's l1: 0.293259\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000219 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.777838\tvalid_0's binary_logloss: 0.437697\tvalid_0's l1: 0.288775\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000215 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.772696\tvalid_0's binary_logloss: 0.444792\tvalid_0's l1: 0.297906\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.775311\tvalid_0's binary_logloss: 0.436933\tvalid_0's l1: 0.288174\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000271 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.768945\tvalid_0's binary_logloss: 0.49023\tvalid_0's l1: 0.33133\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001059 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.773262\tvalid_0's binary_logloss: 0.440887\tvalid_0's l1: 0.293259\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000238 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.777838\tvalid_0's binary_logloss: 0.437697\tvalid_0's l1: 0.288775\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000291 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.772696\tvalid_0's binary_logloss: 0.444792\tvalid_0's l1: 0.297906\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000270 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.775311\tvalid_0's binary_logloss: 0.436933\tvalid_0's l1: 0.288174\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000250 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.768945\tvalid_0's binary_logloss: 0.49023\tvalid_0's l1: 0.33133\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000237 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.773262\tvalid_0's binary_logloss: 0.440887\tvalid_0's l1: 0.293259\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000228 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.777838\tvalid_0's binary_logloss: 0.437697\tvalid_0's l1: 0.288775\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.772696\tvalid_0's binary_logloss: 0.444792\tvalid_0's l1: 0.297906\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.775311\tvalid_0's binary_logloss: 0.436933\tvalid_0's l1: 0.288174\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000230 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.768945\tvalid_0's binary_logloss: 0.49023\tvalid_0's l1: 0.33133\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.773262\tvalid_0's binary_logloss: 0.440887\tvalid_0's l1: 0.293259\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000383 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.777838\tvalid_0's binary_logloss: 0.437697\tvalid_0's l1: 0.288775\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000222 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.772696\tvalid_0's binary_logloss: 0.444792\tvalid_0's l1: 0.297906\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.775311\tvalid_0's binary_logloss: 0.436933\tvalid_0's l1: 0.288174\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000147 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.768945\tvalid_0's binary_logloss: 0.49023\tvalid_0's l1: 0.33133\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000231 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.773262\tvalid_0's binary_logloss: 0.440887\tvalid_0's l1: 0.293259\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.777838\tvalid_0's binary_logloss: 0.437697\tvalid_0's l1: 0.288775\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.772696\tvalid_0's binary_logloss: 0.444792\tvalid_0's l1: 0.297906\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000235 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.775311\tvalid_0's binary_logloss: 0.436933\tvalid_0's l1: 0.288174\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.768945\tvalid_0's binary_logloss: 0.49023\tvalid_0's l1: 0.33133\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001107 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.773262\tvalid_0's binary_logloss: 0.440887\tvalid_0's l1: 0.293259\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000228 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.777838\tvalid_0's binary_logloss: 0.437697\tvalid_0's l1: 0.288775\n",
      "[LightGBM] [Info] Number of positive: 4280, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19028, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224932 -> initscore=-1.237154\n",
      "[LightGBM] [Info] Start training from score -1.237154\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.772696\tvalid_0's binary_logloss: 0.444792\tvalid_0's l1: 0.297906\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000229 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.775311\tvalid_0's binary_logloss: 0.436933\tvalid_0's l1: 0.288174\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000217 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.768945\tvalid_0's binary_logloss: 0.49023\tvalid_0's l1: 0.33133\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.773262\tvalid_0's binary_logloss: 0.440887\tvalid_0's l1: 0.293259\n",
      "[LightGBM] [Info] Number of positive: 4281, number of negative: 14748\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1663\n",
      "[LightGBM] [Info] Number of data points in the train set: 19029, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224972 -> initscore=-1.236921\n",
      "[LightGBM] [Info] Start training from score -1.236921\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.777838\tvalid_0's binary_logloss: 0.437697\tvalid_0's l1: 0.288775\n",
      "[LightGBM] [Info] Number of positive: 5351, number of negative: 18435\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001528 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 23786, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224964 -> initscore=-1.236968\n",
      "[LightGBM] [Info] Start training from score -1.236968\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.777573\tvalid_0's binary_logloss: 0.440346\tvalid_0's l1: 0.293318\n",
      "Best parameters found by grid search are: {'learning_rate': 0.2, 'n_estimators': 20}\n"
     ]
    }
   ],
   "source": [
    "# Remake our test/train set with our reduced dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=21)\n",
    "\n",
    "reduc_estimator = lgb.LGBMClassifier(learning_rate = 0.125, metric = 'l1', \n",
    "                        n_estimators = 20, num_leaves = 38)\n",
    "\n",
    "# Parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [x for x in range(20, 36, 2)],\n",
    "    'learning_rate': [0.10, 0.125, 0.15, 0.175, 0.2]}\n",
    "\n",
    "gridsearch = GridSearchCV(reduc_estimator, param_grid)\n",
    "\n",
    "gridsearch.fit(X_train, y_train,\n",
    "        eval_set = [(X_test, y_test)],\n",
    "        eval_metric = ['auc', 'binary_logloss'],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=3),\n",
    "        ]\n",
    "        )\n",
    "print('Best parameters found by grid search are:', gridsearch.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5351, number of negative: 18435\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1664\n",
      "[LightGBM] [Info] Number of data points in the train set: 23786, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.224964 -> initscore=-1.236968\n",
      "[LightGBM] [Info] Start training from score -1.236968\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.772154\tvalid_0's binary_logloss: 0.507923\tvalid_0's binary_error: 0.220961\tvalid_0's l1: 0.338962\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-24 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-24 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-24 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-24 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-24 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-24 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-24 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-24 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-24 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-24 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-24 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-24 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-24 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-24 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-24 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-24 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-24 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-24 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-24 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-24 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-24 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-24 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-24\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(metric=&#x27;l1&#x27;, n_estimators=20)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" checked><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LGBMClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(metric=&#x27;l1&#x27;, n_estimators=20)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(metric='l1', n_estimators=20)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm = lgb.LGBMClassifier(learning_rate = 0.1, metric = 'l1', \n",
    "                        n_estimators = 20)\n",
    "gbm.fit(X_train, y_train,\n",
    "        eval_set=[(X_test, y_test)],\n",
    "        eval_metric=['auc', 'binary_logloss', 'binary_error'],\n",
    "        callbacks=[\n",
    "                lgb.early_stopping(stopping_rounds=3),\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>We still need to compare the <b>classification accuracy </b> versus the <b>null accuracy</b> ( the accuracy that could be achieved by always predicting the most frequent class). We must always compare the two.  </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of prediction is: 0.7790389708664397\n",
      "The roc_auc_score of prediction is: 0.5\n",
      "The null acccuracy is: 0.7790389708664396\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    2643.0\n",
       "mean        0.0\n",
       "std         0.0\n",
       "min         0.0\n",
       "25%         0.0\n",
       "50%         0.0\n",
       "75%         0.0\n",
       "max         0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration_)\n",
    "print('The accuracy of prediction is:', accuracy_score(y_test, y_pred))\n",
    "print('The roc_auc_score of prediction is:', roc_auc_score(y_test, y_pred))\n",
    "print('The null acccuracy is:', max(y_test.mean(), 1 - y_test.mean()))\n",
    "pd.Series(y_pred).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = gbm.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21148627, 0.2314076 , 0.2191977 , ..., 0.22087094, 0.22318443,\n",
       "       0.21148627])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.title('ROC curve for credit card defaulting classifier')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC with dimensionality reduction: \n",
      "0.7721538251711497\n",
      "AUC without dimensionality reduction: \n",
      "0.7749700285270646\n"
     ]
    }
   ],
   "source": [
    "auc_roc_1 = str(roc_auc_score(y_test, y_pred_prob))\n",
    "print('AUC with dimensionality reduction: \\n' + auc_roc_1)\n",
    "print('AUC without dimensionality reduction: \\n' + auc_roc_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Conclusion</h2>\n",
    "We were able to reduce the size of our training/test set by 26% by removing 6 features, while only giving up 0.52% in our AUC accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- AUC is useful as a single number summary of classifier performance\n",
    "- Higher value means that it is a better classifier\n",
    "- If you randomly chose one positive and one negative observation, AUC represents the likelihood that your classifier will assign a higher predicted probability to the positive observation\n",
    "- AUC is useful even when there is high class imbalance (unlike classification accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a good thing that the prediction accuracy is greater than the null accuracy because it shows us that the model is performing better than by just predicting the most frequent class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Confusion matrix </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2059    0]\n",
      " [ 584    0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<b>Basic terminology</b>\n",
    "\n",
    "- <b>True Positives (TP)</b>: we correctly predicted that they would default. \n",
    "    - 233\n",
    "     \n",
    "     \n",
    "- <b>True Negatives (TN)</b>: we correctly predicted that they won't default.\n",
    "    - 2252\n",
    "     \n",
    "    \n",
    "- <b>False Positives (FP)</b>: we incorrectly predicted that they did default.\n",
    "    - 108\n",
    "    - Falsely predict positive\n",
    "    - Type I error\n",
    "      \n",
    "       \n",
    "- <b>False Negatives (FN)</b>: we incorrectly predicted that they didn't default. \n",
    "    - 407\n",
    "    - Falsely predict negative\n",
    "    - Type II error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
